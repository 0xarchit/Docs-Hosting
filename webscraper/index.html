<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="turbo-cache-control" content="no-cache" data-turbo-track="reload" data-track-token="3.11.0.809408620147">

    <!-- See retype.com -->
    <meta name="generator" content="Retype 3.11.0">

    <!-- Primary Meta Tags -->
    <title> Web Scraper Collection | 0xArchit Projects Documentation</title>
    <meta name="title" content=" Web Scraper Collection | 0xArchit Projects Documentation">
    <meta name="description" content="A collection of web scrapers: a Python-based DuckDuckGo Lite scraper and a Cloudflare Worker Jina AI & Groq LLM scraper.">

    <!-- Canonical -->
    <link rel="canonical" href="https://docs.0xarchit.is-a.dev/webscraper/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://docs.0xarchit.is-a.dev/webscraper/">
    <meta property="og:title" content=" Web Scraper Collection | 0xArchit Projects Documentation">
    <meta property="og:description" content="A collection of web scrapers: a Python-based DuckDuckGo Lite scraper and a Cloudflare Worker Jina AI & Groq LLM scraper.">
    <meta property="og:image" content="https://img.shields.io/badge/Cloudflare-orange">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://docs.0xarchit.is-a.dev/webscraper/">
    <meta property="twitter:title" content=" Web Scraper Collection | 0xArchit Projects Documentation">
    <meta property="twitter:description" content="A collection of web scrapers: a Python-based DuckDuckGo Lite scraper and a Cloudflare Worker Jina AI & Groq LLM scraper.">
    <meta property="twitter:image" content="https://img.shields.io/badge/Cloudflare-orange">

    <script data-cfasync="false">(function(){var cl=document.documentElement.classList,ls=localStorage.getItem("retype_scheme"),hd=cl.contains("dark"),hl=cl.contains("light"),wm=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;if(ls==="dark"||(!ls&&wm&&!hd&&!hl)){cl.remove("light");cl.add("dark")}else if(ls==="light"||(!ls&&!wm&&!hd&&!hl)){cl.remove("dark");cl.add("light")}})();</script>

    <link href="../public/0xarchit.ico" rel="icon">
    <link href="../resources/css/retype.css?v=3.11.0.809408620147" rel="stylesheet">

    <script data-cfasync="false" src="../resources/js/config.js?v=3.11.0.809408620147" data-turbo-eval="false" defer></script>
    <script data-cfasync="false" src="../resources/js/retype.js?v=3.11.0" data-turbo-eval="false" defer></script>
    <script id="lunr-js" data-cfasync="false" src="../resources/js/lunr.js?v=3.11.0.809408620147" data-turbo-eval="false" defer></script>
    <script id="prism-js" data-cfasync="false" src="../resources/js/prism.js?v=3.11.0.809408620147" defer></script>
</head>
<body>
    <div id="retype-app" class="relative text-base antialiased text-base-text bg-base-bg font-body">
        <div class="absolute bottom-0 left-0" style="top: 5rem; right: 50%"></div>
    
        <header id="retype-header" class="sticky top-0 z-30 flex w-full h-16 bg-header-bg border-b border-header-border md:h-20">
            <div class="container relative flex items-center justify-between pr-6 grow md:justify-start">
                <!-- Mobile menu button skeleton -->
                <button v-cloak class="skeleton retype-mobile-menu-button flex items-center justify-center shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
                <div v-cloak id="retype-sidebar-left-toggle-button"></div>
        
                <!-- Logo -->
                <div class="flex items-center justify-between h-full py-2 md:w-75">
                    <div class="flex items-center px-2 md:px-6">
                        <a id="retype-branding-logo" href="../" class="flex items-center leading-snug text-2xl">
                            <span class="w-10 mr-2 grow-0 shrink-0 overflow-hidden">
                                <img class="max-h-10 dark:hidden md:inline-block" src="../public/0xarchit.webp">
                                <img class="max-h-10 hidden dark:inline-block" src="../public/0xarchit.webp">
                            </span>
                            <span class="dark:text-white font-bold line-clamp-1 md:line-clamp-2">0xArchit</span>
                        </a><span id="retype-branding-label" class="inline-flex mt-1 px-2 py-1 ml-4 text-xs font-medium leading-none items-center rounded-md bg-branding-label-bg text-branding-label-text ring-1 ring-branding-label-border ring-inset md:inline-block">Docs</span>
                    </div>
        
                    <span class="hidden h-8 border-r md:inline-block border-base-border"></span>
                </div>
        
                <div class="flex justify-between md:grow">
                    <!-- Top Nav -->
                    <nav id="retype-header-nav" class="hidden md:flex">
                        <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
                            
                        </ul>
                    </nav>
        
                    <!-- Header Right Skeleton -->
                    <div v-cloak class="flex justify-end grow skeleton">
        
                        <!-- Search input mock -->
                        <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                            <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                                <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                            </div>
                            <input class="w-full h-10 placeholder-search-placeholder transition-colors duration-200 ease-in bg-search-bg border border-transparent rounded md:text-sm hover:border-search-border-hover focus:outline-none focus:border-search-border-focus" style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search docs...">
                        </div>
        
                        <!-- Mobile search button -->
                        <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                        </div>
        
                        <!-- Dark mode switch placeholder -->
                        <div class="w-10 h-10 lg:ml-2"></div>
        
                        <!-- History button -->
                        <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                        </div>
                    </div>
        
                    <div v-cloak class="flex justify-end grow">
                        <div id="retype-mobile-search-button"></div>
                        <doc-search-desktop></doc-search-desktop>
        
                        <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                        <doc-history></doc-history>
                    </div>
                </div>
            </div>
        </header>
    
    
        <div id="retype-container" class="container relative flex bg-white">
            <!-- Sidebar Skeleton -->
            <div v-cloak class="fixed flex flex-col shrink-0 duration-300 ease-in-out bg-sidebar-left-bg border-sidebar-left-border sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton">
            
                <div class="flex items-center h-16 px-6">
                    <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-filter-bg border border-filter-border rounded shadow-none text-sm focus:outline-none focus:border-filter-border-focus" type="text" placeholder="Filter">
                </div>
            
                <div class="pl-6 mt-1 mb-4">
                    <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                </div>
            
                <div class="shrink-0 mt-auto bg-transparent dark:border-base-border">
                    <a class="flex items-center justify-center flex-nowrap h-16 text-gray-350 dark:text-dark-400 hover:text-gray-600 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                        <span class="text-xs whitespace-nowrap">Powered by</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                    </a>
                </div>
            </div>
            
            <!-- Sidebar component -->
            <doc-sidebar v-cloak>
                <template #sidebar-footer>
                    <div class="shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-base-border">
            
                        <a class="flex items-center justify-center flex-nowrap h-16 text-gray-350 dark:text-dark-400 hover:text-gray-600 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                            <span class="text-xs whitespace-nowrap">Powered by</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                        </a>
                    </div>
                </template>
            </doc-sidebar>
    
            <div class="grow min-w-0 bg-body-bg">
                <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
                <div class="flex">
                    <div id="retype-main" class="min-w-0 p-4 grow md:px-16">
                        <main class="relative pb-12 lg:pt-2">
                            <div class="retype-markdown" id="retype-content">
                                <!-- Rendered if sidebar right is enabled -->
                                <div id="retype-sidebar-right-toggle"></div>
                                <!-- Page content  -->
<doc-anchor-target id="web-scraper-collection" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#web-scraper-collection">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M0 3.75C0 2.784.784 2 1.75 2h20.5c.966 0 1.75.784 1.75 1.75v16.5A1.75 1.75 0 0 1 22.25 22H1.75A1.75 1.75 0 0 1 0 20.25ZM22.5 7h-21v13.25c0 .138.112.25.25.25h20.5a.25.25 0 0 0 .25-.25Zm-10-3.5v2h10V3.75a.25.25 0 0 0-.25-.25ZM7 3.5v2h4v-2Zm-5.25 0a.25.25 0 0 0-.25.25V5.5h4v-2Z"/></g></g></svg> Web Scraper Collection</span>
    </h1>
</doc-anchor-target>
<p><img src="https://img.shields.io/badge/Cloudflare-orange" alt="" /> <img src="https://img.shields.io/badge/Python-3.11-blue" alt="" /> <img src="https://img.shields.io/badge/JavaScript-yellow" alt="" /></p>
<p><strong><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"/></g></g></svg> GitHub:</strong> <a href="https://github.com/0xarchit/duckduckgo-webscraper" target="_blank">0xarchit/duckduckgo-webscraper</a><br />
<strong><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm3.241 10.5v-.001c-.1-2.708-.992-4.904-1.89-6.452a13.919 13.919 0 0 0-1.304-1.88L12 3.11l-.047.059c-.354.425-.828 1.06-1.304 1.88-.898 1.547-1.79 3.743-1.89 6.451Zm-12.728 0h4.745c.1-3.037 1.1-5.49 2.093-7.204.39-.672.78-1.233 1.119-1.673C6.11 3.329 2.746 7 2.513 11.5Zm18.974 0C21.254 7 17.89 3.329 13.53 2.623c.339.44.729 1.001 1.119 1.673.993 1.714 1.993 4.167 2.093 7.204ZM8.787 13c.182 2.478 1.02 4.5 1.862 5.953.382.661.818 1.29 1.304 1.88l.047.057.047-.059c.354-.425.828-1.06 1.304-1.88.842-1.451 1.679-3.471 1.862-5.951Zm-1.504 0H2.552a9.505 9.505 0 0 0 7.918 8.377 15.773 15.773 0 0 1-1.119-1.673C8.413 18.085 7.47 15.807 7.283 13Zm9.434 0c-.186 2.807-1.13 5.085-2.068 6.704-.39.672-.78 1.233-1.118 1.673A9.506 9.506 0 0 0 21.447 13Z"/></g></g></svg> Live Demo:</strong> <a href="https://duckduckgo-webscraper.onrender.com">https://duckduckgo-webscraper.onrender.com</a><br />
<strong><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm3.241 10.5v-.001c-.1-2.708-.992-4.904-1.89-6.452a13.919 13.919 0 0 0-1.304-1.88L12 3.11l-.047.059c-.354.425-.828 1.06-1.304 1.88-.898 1.547-1.79 3.743-1.89 6.451Zm-12.728 0h4.745c.1-3.037 1.1-5.49 2.093-7.204.39-.672.78-1.233 1.119-1.673C6.11 3.329 2.746 7 2.513 11.5Zm18.974 0C21.254 7 17.89 3.329 13.53 2.623c.339.44.729 1.001 1.119 1.673.993 1.714 1.993 4.167 2.093 7.204ZM8.787 13c.182 2.478 1.02 4.5 1.862 5.953.382.661.818 1.29 1.304 1.88l.047.057.047-.059c.354-.425.828-1.06 1.304-1.88.842-1.451 1.679-3.471 1.862-5.951Zm-1.504 0H2.552a9.505 9.505 0 0 0 7.918 8.377 15.773 15.773 0 0 1-1.119-1.673C8.413 18.085 7.47 15.807 7.283 13Zm9.434 0c-.186 2.807-1.13 5.085-2.068 6.704-.39.672-.78 1.233-1.118 1.673A9.506 9.506 0 0 0 21.447 13Z"/></g></g></svg> Live Demo:</strong>  <a href="https://webscrape.0xcloud.workers.dev/?key=test&amp;query=">https://webscrape.0xcloud.workers.dev/?key=test&amp;query=</a></p>
<doc-anchor-target id="web-scraper-collection-1">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#web-scraper-collection-1">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M0 3.75C0 2.784.784 2 1.75 2h20.5c.966 0 1.75.784 1.75 1.75v16.5A1.75 1.75 0 0 1 22.25 22H1.75A1.75 1.75 0 0 1 0 20.25ZM22.5 7h-21v13.25c0 .138.112.25.25.25h20.5a.25.25 0 0 0 .25-.25Zm-10-3.5v2h10V3.75a.25.25 0 0 0-.25-.25ZM7 3.5v2h4v-2Zm-5.25 0a.25.25 0 0 0-.25.25V5.5h4v-2Z"/></g></g></svg> Web Scraper Collection</span>
    </h1>
</doc-anchor-target>
<p>A collection of web scraper/content scrapers with two major approaches:</p>
<ol>
<li><strong>Python-based DuckDuckGo Scraper</strong>: Uses DuckDuckGo Lite search to fetch top result pages (default 3, customizable), then extracts structured content (titles, descriptions, headings, summaries, links, and more).</li>
<li><strong>Cloudflare Worker Scraper</strong>: Fetches search results via Jina AI and DuckDuckGo, retrieves page content, analyzes it with Groq LLM API, and rotates through multiple API keys using GetPantry.</li>
</ol>
<doc-anchor-target id="python-based-duckduckgo-scraper">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#python-based-duckduckgo-scraper">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M3 3a2 2 0 0 1 2-2h9.982a2 2 0 0 1 1.414.586l4.018 4.018A2 2 0 0 1 21 7.018V21a2 2 0 0 1-2 2H4.75a.75.75 0 0 1 0-1.5H19a.5.5 0 0 0 .5-.5V8.5h-4a2 2 0 0 1-2-2v-4H5a.5.5 0 0 0-.5.5v6.25a.75.75 0 0 1-1.5 0Zm12-.5v4a.5.5 0 0 0 .5.5h4a.5.5 0 0 0-.146-.336l-4.018-4.018A.5.5 0 0 0 15 2.5Z"/><path d="M4.53 12.24a.75.75 0 0 1-.039 1.06l-2.639 2.45 2.64 2.45a.75.75 0 1 1-1.022 1.1l-3.23-3a.75.75 0 0 1 0-1.1l3.23-3a.75.75 0 0 1 1.06.04Zm3.979 1.06a.75.75 0 1 1 1.02-1.1l3.231 3a.75.75 0 0 1 0 1.1l-3.23 3a.75.75 0 1 1-1.021-1.1l2.639-2.45-2.64-2.45Z"/></g></g></svg> Python-based DuckDuckGo Scraper</span>
    </h2>
</doc-anchor-target>
<doc-anchor-target id="features">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#features">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M21.03 5.72a.75.75 0 0 1 0 1.06l-11.5 11.5a.747.747 0 0 1-1.072-.012l-5.5-5.75a.75.75 0 1 1 1.084-1.036l4.97 5.195L19.97 5.72a.75.75 0 0 1 1.06 0Z"/></g></g></svg> Features</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Uses DuckDuckGo Lite search for query results</li>
<li>Rotates through a free proxy list sourced from GitHub</li>
<li>Extracts page title, meta description, main heading, first paragraphs, links, emails, authors, dates, and JSON-LD data</li>
<li>Skips ad redirects and handles failures gracefully</li>
</ul>
<doc-anchor-target id="requirements">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#requirements">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M10.75 6.5a.75.75 0 0 0 0 1.5h6.5a.75.75 0 0 0 0-1.5h-6.5ZM6 7.25a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 6 7.25Zm4 9a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-3.25-.75a.75.75 0 0 0 0 1.5h.5a.75.75 0 0 0 0-1.5h-.5Z"/><path d="M3.25 2h17.5c.966 0 1.75.784 1.75 1.75v7c0 .372-.116.716-.314 1 .198.284.314.628.314 1v7a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75v-7c0-.358.109-.707.314-1a1.741 1.741 0 0 1-.314-1v-7C1.5 2.784 2.284 2 3.25 2Zm0 10.5a.25.25 0 0 0-.25.25v7c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-7a.25.25 0 0 0-.25-.25Zm0-1.5h17.5a.25.25 0 0 0 .25-.25v-7a.25.25 0 0 0-.25-.25H3.25a.25.25 0 0 0-.25.25v7c0 .138.112.25.25.25Z"/></g></g></svg> Requirements</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Python 3.7+</li>
<li>requests</li>
<li>beautifulsoup4</li>
<li>lxml</li>
</ul>
<doc-anchor-target id="installation">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#installation">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M11.25 9.331V.75a.75.75 0 0 1 1.5 0v8.58l1.949-2.11A.75.75 0 1 1 15.8 8.237l-3.25 3.52a.75.75 0 0 1-1.102 0l-3.25-3.52A.75.75 0 1 1 9.3 7.22l1.949 2.111Z"/><path d="M2.5 3.75v11.5c0 .138.112.25.25.25h18.5a.25.25 0 0 0 .25-.25V3.75a.25.25 0 0 0-.25-.25h-5.5a.75.75 0 0 1 0-1.5h5.5c.966 0 1.75.784 1.75 1.75v11.5A1.75 1.75 0 0 1 21.25 17h-6.204c.171 1.375.805 2.652 1.769 3.757A.752.752 0 0 1 16.25 22h-8.5a.75.75 0 0 1-.566-1.243c.965-1.105 1.599-2.382 1.77-3.757H2.75A1.75 1.75 0 0 1 1 15.25V3.75C1 2.784 1.784 2 2.75 2h5.5a.75.75 0 0 1 0 1.5h-5.5a.25.25 0 0 0-.25.25ZM10.463 17c-.126 1.266-.564 2.445-1.223 3.5h5.52c-.66-1.055-1.098-2.234-1.223-3.5Z"/></g></g></svg> Installation</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-powershell"><code v-pre class="language-powershell">git clone https://github.com/0xarchit/duckduckgo-webscraper.git
cd duckduckgo-webscraper
pip install -r requirements.txt</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="usage">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#usage">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M9.5 15.584V8.416a.5.5 0 0 1 .77-.42l5.576 3.583a.5.5 0 0 1 0 .842l-5.576 3.584a.5.5 0 0 1-.77-.42Z"/><path d="M1 12C1 5.925 5.925 1 12 1s11 4.925 11 11-4.925 11-11 11S1 18.075 1 12Zm11-9.5A9.5 9.5 0 0 0 2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5Z"/></g></g></svg> Usage</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-powershell"><code v-pre class="language-powershell">python basescript\scraper_base.py</code></pre>
</doc-codeblock></div>
<ul>
<li>Prompts for a search query</li>
<li>Default <code v-pre>max_results</code> is 3 (adjust in <code v-pre>webscraper.py</code>)</li>
</ul>
<doc-anchor-target id="configuration">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#configuration">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M16 12a4 4 0 1 1-8 0 4 4 0 0 1 8 0Zm-1.5 0a2.5 2.5 0 1 0-5 0 2.5 2.5 0 0 0 5 0Z"/><path d="M12 1c.266 0 .532.009.797.028.763.055 1.345.617 1.512 1.304l.352 1.45c.019.078.09.171.225.221.247.089.49.19.728.302.13.061.246.044.315.002l1.275-.776c.603-.368 1.411-.353 1.99.147.402.349.78.726 1.128 1.129.501.578.515 1.386.147 1.99l-.776 1.274c-.042.069-.058.185.002.315.112.238.213.481.303.728.048.135.142.205.22.225l1.45.352c.687.167 1.249.749 1.303 1.512.038.531.038 1.063 0 1.594-.054.763-.616 1.345-1.303 1.512l-1.45.352c-.078.019-.171.09-.221.225-.089.248-.19.491-.302.728-.061.13-.044.246-.002.315l.776 1.275c.368.603.353 1.411-.147 1.99-.349.402-.726.78-1.129 1.128-.578.501-1.386.515-1.99.147l-1.274-.776c-.069-.042-.185-.058-.314.002a8.606 8.606 0 0 1-.729.303c-.135.048-.205.142-.225.22l-.352 1.45c-.167.687-.749 1.249-1.512 1.303-.531.038-1.063.038-1.594 0-.763-.054-1.345-.616-1.512-1.303l-.352-1.45c-.019-.078-.09-.171-.225-.221a8.138 8.138 0 0 1-.728-.302c-.13-.061-.246-.044-.315-.002l-1.275.776c-.603.368-1.411.353-1.99-.147-.402-.349-.78-.726-1.128-1.129-.501-.578-.515-1.386-.147-1.99l.776-1.274c.042-.069.058-.185-.002-.314a8.606 8.606 0 0 1-.303-.729c-.048-.135-.142-.205-.22-.225l-1.45-.352c-.687-.167-1.249-.749-1.304-1.512a11.158 11.158 0 0 1 0-1.594c.055-.763.617-1.345 1.304-1.512l1.45-.352c.078-.019.171-.09.221-.225.089-.248.19-.491.302-.728.061-.13.044-.246.002-.315l-.776-1.275c-.368-.603-.353-1.411.147-1.99.349-.402.726-.78 1.129-1.128.578-.501 1.386-.515 1.99-.147l1.274.776c.069.042.185.058.315-.002.238-.112.481-.213.728-.303.135-.048.205-.142.225-.22l.352-1.45c.167-.687.749-1.249 1.512-1.304C11.466 1.01 11.732 1 12 1Zm-.69 1.525c-.055.004-.135.05-.161.161l-.353 1.45a1.832 1.832 0 0 1-1.172 1.277 7.147 7.147 0 0 0-.6.249 1.833 1.833 0 0 1-1.734-.074l-1.274-.776c-.098-.06-.186-.036-.228 0a9.774 9.774 0 0 0-.976.976c-.036.042-.06.131 0 .228l.776 1.274c.314.529.342 1.18.074 1.734a7.147 7.147 0 0 0-.249.6 1.831 1.831 0 0 1-1.278 1.173l-1.45.351c-.11.027-.156.107-.16.162a9.63 9.63 0 0 0 0 1.38c.004.055.05.135.161.161l1.45.353a1.832 1.832 0 0 1 1.277 1.172c.074.204.157.404.249.6.268.553.24 1.204-.074 1.733l-.776 1.275c-.06.098-.036.186 0 .228.301.348.628.675.976.976.042.036.131.06.228 0l1.274-.776a1.83 1.83 0 0 1 1.734-.075c.196.093.396.176.6.25a1.831 1.831 0 0 1 1.173 1.278l.351 1.45c.027.11.107.156.162.16a9.63 9.63 0 0 0 1.38 0c.055-.004.135-.05.161-.161l.353-1.45a1.834 1.834 0 0 1 1.172-1.278 6.82 6.82 0 0 0 .6-.248 1.831 1.831 0 0 1 1.733.074l1.275.776c.098.06.186.036.228 0 .348-.301.675-.628.976-.976.036-.042.06-.131 0-.228l-.776-1.275a1.834 1.834 0 0 1-.075-1.733c.093-.196.176-.396.25-.6a1.831 1.831 0 0 1 1.278-1.173l1.45-.351c.11-.027.156-.107.16-.162a9.63 9.63 0 0 0 0-1.38c-.004-.055-.05-.135-.161-.161l-1.45-.353c-.626-.152-1.08-.625-1.278-1.172a6.576 6.576 0 0 0-.248-.6 1.833 1.833 0 0 1 .074-1.734l.776-1.274c.06-.098.036-.186 0-.228a9.774 9.774 0 0 0-.976-.976c-.042-.036-.131-.06-.228 0l-1.275.776a1.831 1.831 0 0 1-1.733.074 6.88 6.88 0 0 0-.6-.249 1.835 1.835 0 0 1-1.173-1.278l-.351-1.45c-.027-.11-.107-.156-.162-.16a9.63 9.63 0 0 0-1.38 0Z"/></g></g></svg> Configuration</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Proxy URL in <code v-pre>fetch_proxies()</code> of <code v-pre>webscraper.py</code></li>
<li>Change <code v-pre>max_results</code> to adjust page count per query</li>
<li>Tweak <code v-pre>time.sleep()</code> delays for rate limiting</li>
</ul>
<doc-anchor-target id="sample-output">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#sample-output">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M3.604 3.089A.75.75 0 0 1 4 3.75V8.5h.75a.75.75 0 0 1 0 1.5h-3a.75.75 0 1 1 0-1.5h.75V5.151l-.334.223a.75.75 0 0 1-.832-1.248l1.5-1a.75.75 0 0 1 .77-.037ZM8.75 5.5a.75.75 0 0 0 0 1.5h11.5a.75.75 0 0 0 0-1.5H8.75Zm0 6a.75.75 0 0 0 0 1.5h11.5a.75.75 0 0 0 0-1.5H8.75Zm0 6a.75.75 0 0 0 0 1.5h11.5a.75.75 0 0 0 0-1.5H8.75ZM5.5 15.75c0-.704-.271-1.286-.72-1.686a2.302 2.302 0 0 0-1.53-.564c-.535 0-1.094.178-1.53.565-.449.399-.72.982-.72 1.685a.75.75 0 0 0 1.5 0c0-.296.104-.464.217-.564A.805.805 0 0 1 3.25 15c.215 0 .406.072.533.185.113.101.217.268.217.565 0 .332-.069.48-.21.657-.092.113-.216.24-.403.419l-.147.14c-.152.144-.33.313-.52.504l-1.5 1.5a.75.75 0 0 0-.22.53v.25c0 .414.336.75.75.75H5A.75.75 0 0 0 5 19H3.31l.47-.47c.176-.176.333-.324.48-.465l.165-.156a5.98 5.98 0 0 0 .536-.566c.358-.447.539-.925.539-1.593Z"/></g></g></svg> Sample Output</span>
    </h3>
</doc-anchor-target>
<doc-panel id="click-to-expand" collapsed>
    <template #title>Click to expand</template>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">======================================================================
                     🌐 DuckDuckGo Query Scraper 🌐
                            By 0xArchit
======================================================================

🔎 Enter your search query: Gen AI
🚀 Fetching fresh proxy list...
✅ Loaded 2393 proxies.

🔍 Initiating DuckDuckGo Lite search for: 'Gen AI'

🔌 Testing proxy: 51.81.245.3:17981
✅ Proxy working: 51.81.245.3:17981
🌐 Attempt 1/5 Scraping: https://lite.duckduckgo.com/lite/?q=Gen AI with proxy: http://51.81.245.3:17981
  ✅ Successfully scraped https://lite.duckduckgo.com/lite/?q=Gen AI
⏳ Waiting 5 seconds after DuckDuckGo search to avoid rate limits...

➡️ Found result: 'What is generative AI? - IBM'
   🔗 Link: https://www.ibm.com/think/topics/generative-ai
⏳ Waiting 5 seconds before scraping this result page...
🌐 Attempt 1/5 Scraping: https://www.ibm.com/think/topics/generative-ai with proxy: http://51.81.245.3:17981
  ✅ Successfully scraped https://www.ibm.com/think/topics/generative-ai

➡️ Found result: 'Generative artificial intelligence - Wikipedia'
   🔗 Link: https://en.wikipedia.org/wiki/Generative_artificial_intelligence
⏳ Waiting 5 seconds before scraping this result page...
🌐 Attempt 1/5 Scraping: https://en.wikipedia.org/wiki/Generative_artificial_intelligence with proxy: http://51.81.245.3:17981
  ✅ Successfully scraped https://en.wikipedia.org/wiki/Generative_artificial_intelligence

➡️ Found result: 'What is Generative AI? - GeeksforGeeks'
   🔗 Link: https://www.geeksforgeeks.org/artificial-intelligence/what-is-generative-ai/
⏳ Waiting 5 seconds before scraping this result page...
🌐 Attempt 1/5 Scraping: https://www.geeksforgeeks.org/artificial-intelligence/what-is-generative-ai/ with proxy: http://51.81.245.3:17981
  ✅ Successfully scraped https://www.geeksforgeeks.org/artificial-intelligence/what-is-generative-ai/

==================== UNIVERSAL SCRAPE REPORT ====================


---------- ✨ RESULT #1 ✨ ----------------------------------------

  📌 Title: What is generative AI? - IBM
  🌐 URL  : https://www.ibm.com/think/topics/generative-ai

  📊 Detailed Analysis (General Web Page):
    - Url: https://www.ibm.com/think/topics/generative-ai
    - Title: What is Generative AI?  | IBM
    - Meta Description: Generative AI is artificial intelligence (AI) that can create original content in response to a user’s prompt or request.
    - Main Heading: What is generative AI?
    - Summary Text: Editorial Lead, AI Models  Editor, Topics &amp; Insights for IBM Think  Generative AI, sometimes calledgen AI,isartificial intelligence(AI) that can create original content such as text, images, video, audio or software code in response to a user’s prompt or request.
    - Links: (Complex Data - See raw content)
    - Email: xxx@ccc.com
    - Keywords: Generative AI
    - Author: Cole Stryker
    - Published Date: Not specified
    - Structured Data: (Complex Data - See raw content)

  📄 Raw Content Excerpt:
    What is Generative AI? | IBM What is generative AI? 22 March 2024
    Link copied Authors Cole Stryker Editorial Lead, AI Models Mark
    Scapicchio Editor, Topics &amp; Insights for IBM Think What is
    generative AI? Generative AI, sometimes called gen AI, is
    artificial intelligence (AI) that can create original content such
    as text, images, video, audio or software code in response to a
    user’s prompt or request. Generative AI relies on sophisticated
    machine learning models called deep learning models algorithms
    that simulate the learning and decision-making processes of the
    human brain. These models work by identifying and encoding the
    patterns and relationships in huge amounts of data, and then using
    that information to understand users' natural language requests or
    questions and respond with relevant new content. AI has been a hot
    technology topic for the past decade, but generative AI, and
    specifically the arrival of ChatGPT in 2022, has thrust AI into
    worldwide headlines and launched an unprecedented surge of AI
    innovation and adoption. Generative AI offers enormous
    productivity benefits for individuals and organizations, and while
    it also presents very real challenges and risks, businesses are
    forging ahead, exploring how the technology can improve their
    internal workflows and enrich their products and services.
    According to research by the management consulting firm McKinsey,
    one third of organizations are already using generative AI
    regularly in at least one business function.¹ Industry analyst
    Gartner projects more than 80% of organizations will have deployed
    generative AI applications or used generative AI application
    programming interfaces (APIs) by 2026. 2 How generative AI works
    For the most part, generative AI operates in three phases:
    Training , to create a foundation model that can serve as the
    basis of multiple gen AI applications. Tuning , to tailor the
    foundation model to a specific gen AI application. Generation ,
    evaluation and retuning , to assess the gen AI application's
    output and continually improve its quality and accuracy. Training
    Generative AI begins with a foundation model, a deep learning
    model that serves as the basis for multiple different types of
    generative AI applications. The most common foundation models
    today are large language models (LLMs) , created for text
    generation applications, but there are also foundation models for
    image generation, video generation, and sound and music generation
    as well as multimodal foundation models that can support several
    kinds content generation. To create a foundation model,
    practitioners train a deep learning algorithm on huge volumes of
    raw, unstructured, unlabeled data e.g., terabytes of data culled
    from the internet or some other huge data source. During training,
    the algorithm performs and evaluates millions of ‘fill in the
    blank’ exercises, trying to predict the next element in a sequence
    e.g., the next word in a sentence, the next element in an image,
    the next command in a line of code and continually adjusting
    itself to minimize the difference between its predictions and the
    actual data (or ‘correct’ result). The result of this training is
    a neural network of parameters, encoded representations of the
    entities, patterns and relationships in the data, that can
    generate content autonomously in response to inputs, or prompts.
    This training process is compute-intensive, time-consuming and
    expensive: it requires thousands of clustered graphics processing
    units (GPUs) and weeks of processing, all of which costs millions
    of dollars. Open-source foundation model projects, such as Meta's
    Llama-2, enable gen AI developers to avoid this step and its
    costs. Tuning Metaphorically speaking, a foundation model is a
    generalist: It knows a lot about a lot of types of content, but
    often can’t generate specific types of output with desired
    accuracy or fidelity. For that, the model must be tuned to a
    specific content generation task. This can be done in a variety of
    ways. Fine tuning Fine tuning involves feeding the model labeled
    data specific to the content generation application questions or
    prompts the application is likely to receive, and corresponding
    correct answers in the desired format. For example, if a
    development team is trying to create a customer service chatbot,
    it would create hundreds or thousands of documents containing
    labeled customers service questions and correct answers, and then
    feed those documents to the model. Fine-tuning is labor-intensive.
    Developers often outsource the task to companies with large data-
    labeling workforces. Reinforcement learning with human feedback
    (RLHF) In RLHF , human users respond to generated content with
    evaluations the model can use to update the model for greater
    accuracy or relevance. Often, RLHF involves people ‘scoring’
    different outputs in response to the same prompt. But it can be as
    simple as having people type or talk back to a chatbot or virtual
    assistant, correcting its output. Generation, evaluation, more
    tuning Developers and users continually assess the outputs of
    their generative AI apps, and further tune the model even as often
    as once a week for greater accuracy or relevance. (In contrast,
    the foundation model itself is updated much less frequently,
    perhaps every year or 18 months.) Another option for improving a
    gen AI app's performance is retrieval augmented generation (RAG).
    RAG is a framework for extending the foundation model to use
    relevant sources outside of the training data, to supplement and
    refine the parameters or representations in the original model.
    RAG can ensure that a generative AI app always has access to the
    most current information. As a bonus, the additional sources
    accessed via RAG are transparent to users in a way that the
    knowledge in the original foundation model is not. Generative AI
    model architectures and how they have evolved Truly generative AI
    models deep learning models that can autonomously create content
    on demand have evolved over the last dozen years or so. The
    milestone model architectures during that period include
    Variational autoencoders (VAEs) , which drove breakthroughs in
    image recognition, natural language processing and anomaly
    detection. Generative adversarial networks (GANs) and diffusion
    models , which improved the accuracy of previous applications and
    enabled some of the first AI solutions for photo-realistic image
    generation. Transformers , the deep learning model architecture
    behind the foremost foundation models and generative AI solutions
    today. Variational autoencoders (VAEs) An autoencoder is a deep
    learning model comprising two connected neural networks: One that
    encodes (or compresses) a huge amount of unstructured, unlabeled
    training data into parameters, and another that decodes those
    parameters to reconstruct the content. Technically, autoencoders
    can generate new content, but they’re more useful for compressing
    data for storage or transfer, and decompressing it for use, than
    they are for high-quality content generation. Introduced in 2013,
    variational autoencoders (VAEs) can encode data like an
    autoencoder, but decode multiple new variations of the content .
    By training a VAE to generate variations toward a particular goal,
    it can ‘zero in’ on more accurate, higher-fidelity content over
    time. Early VAE applications included anomaly detection (e.g.,
    medical image analysis) and natural language generation.
    Generative adversarial networks (GANs) GANs, introduced in 2014,
    also comprise two neural networks: A generator, which generates
    new content, and a discriminator, which evaluates the accuracy and
    quality the generated data. These adversarial algorithms
    encourages the model to generate increasingly high-quality
    outpits. GANs are commonly used for image and video generation,
    but can generate high-quality, realistic content across various
    domains. They've proven particularly successful at tasks as style
    transfer (altering the style of an image from, say, a photo to a
    pencil sketch) and data augmentation (creating new, synthetic data
    to increase the size and diversity of a training data set).
    Diffusion models Also introduced in 2014, diffusion models work by
    first adding noise to the training data until it’s random and
    unrecognizable, and then training the algorithm to iteratively
    diffuse the noise to reveal a desired output. Diffusion models
    take more time to train than VAEs or GANs, but ultimately offer
    finer-grained control over output, particularly for high-quality
    image generation tool. DALL-E, Open AI’s image-generation tool, is
    driven by a diffusion model. Transformers First documented in a
    2017 paper published by Ashish Vaswani and others, transformers
    evolve the encoder-decoder paradigm to enable a big step forward
    in the way foundation models are trained, and in the quality and
    range of content they can produce. These models are at the core of
    most of today’s headline-making generative AI tools, including
    ChatGPT and GPT-4, Copilot, BERT, Bard, and Midjourney to name a
    few. Transformers use a concept called attention, determining and
    focusing on what’s most important about data within a sequence to;
    process entire sequences of data e.g., sentences instead of
    individual words simultaneously; capture the context of the data
    within the sequence; encode the training data into embeddings
    (also called hyperparameters ) that represent the data and its
    context. In addition to enabling faster training, transformers
    excel at natural language processing (NLP) and natural language
    understanding (NLU), and can generate longer sequences of data
    e.g., not just answers to questions, but poems, articles or papers
    with greater accuracy and higher quality than other deep
    generative AI models. Transformer models can also be trained or
    tuned to use tools e.g., a spreadsheet application, HTML, a
    drawing program to output content in a particular format. What
    generative AI can create Generative AI can create many types of
    content across many different domains. Text Generative models.
    especially those based on transformers, can generate coherent,
    contextually relevant text, everything from instructions and
    documentation to brochures, emails, web site copy, blogs,
    articles, reports, papers, and even creative writing. They can
    also perform repetitive or tedious writing tasks (e.g., such as
    drafting summaries of documents or meta descriptions of web
    pages), freeing writers’ time for more creative, higher-value
    work. Images and video Image generation such as DALL-E, Midjourney
    and Stable Diffusion can create realistic images or original art,
    and can perform style transfer, image-to-image translation and
    other image editing or image enhancement tasks. Emerging gen AI
    video tools can create animations from text prompts, and can apply
    special effects to existing video more quickly and cost-
    effectively than other methods. Sound, speech and music Generative
    models can synthesize natural-sounding speech and audio content
    for voice-enabled AI chatbots and digital assistants, audiobook
    narration and other applications. The same technology can generate
    original music that mimics the structure and sound of professional
    compositions. Software code Gen AI can generate original code,
    autocomplete code snippets, translate between programming
    languages and summarize code functionality. It enables developers
    to quickly prototype, refactor, and debug applications while
    offering a natural language interface for coding tasks. Design and
    art Generative AI models can generate unique works of art and
    design, or assist in graphic design. Applications include dynamic
    generation of environments, characters or avatars, and special
    effects for virtual simulations and video games. Simulations and
    synthetic data Generative AI models can be trained to generate
    synthetic data , or synthetic structures based on real or
    synthetic data. For example, generative AI is applied in drug
    discovery to generate molecular structures with desired
    properties, aiding in the design of new pharmaceutical compounds.
    Industry newsletter The latest AI trends, brought to you by
    experts Get curated insights on the most important—and
    intriguing—AI news. Subscribe to our weekly Think newsletter. See
    the IBM Privacy Statement . Thank you! You are subscribed. Your
    subscription will be delivered in English. You will find an
    unsubscribe link in every newsletter. You can manage your
    subscriptions or unsubscribe here . Refer to our IBM Privacy
    Statement for more informa

------------------------------------------------------------


---------- ✨ RESULT #2 ✨ ----------------------------------------

  📌 Title: Generative artificial intelligence - Wikipedia
  🌐 URL  : https://en.wikipedia.org/wiki/Generative_artificial_intelligence

  📊 Detailed Analysis (General Web Page):
    - Url: https://en.wikipedia.org/wiki/Generative_artificial_intelligence
    - Title: Generative artificial intelligence - Wikipedia
    - Meta Description: No Meta Description
    - Main Heading: Generative artificial intelligence
    - Summary Text:  Generative artificial intelligence(Generative AI,GenAI,[1]orGAI) is a subfield ofartificial intelligencethat usesgenerative modelsto produce text, images, videos, or other forms of data.[2][3][4]These modelslearnthe underlying patterns and structures of theirtraining dataand use them to produce new data[5][6]based on the input, which often comes in the form of natural languageprompts.[7][8] Generative AI tools have become more common since theAI boomin the 2020s. This boom was made possible by improvements intransformer-baseddeepneural networks, particularlylarge language models(LLMs). Major tools includechatbotssuch asChatGPT,Copilot,Gemini,Claude,Grok, andDeepSeek;text-to-imagemodels such asStable Diffusion,Midjourney, andDALL-E; andtext-to-videomodels such asVeoandSora.[9][10][11][12]Technology companies developing generative AI includeOpenAI,Anthropic,Meta AI,Microsoft,Google,DeepSeek, andBaidu.[7][13][14] Generative AI has raised many ethical questions as it can be used forcyb...
    - Links: (Complex Data - See raw content)
    - Keywords: description, artificial, wikipedia, meta, generative, intelligence
    - Author: Contributors to Wikimedia projects
    - Published Date: Not specified
    - Structured Data: (Complex Data - See raw content)

  📄 Raw Content Excerpt:
    Generative artificial intelligence - Wikipedia Jump to content
    From Wikipedia, the free encyclopedia Subset of AI using
    generative models Not to be confused with Artificial general
    intelligence . Théâtre D'opéra Spatial (2022), an image made using
    generative AI Part of a series on Artificial intelligence (AI)
    Major goals Artificial general intelligence Intelligent agent
    Recursive self-improvement Planning Computer vision General game
    playing Knowledge representation Natural language processing
    Robotics AI safety Approaches Machine learning Symbolic Deep
    learning Bayesian networks Evolutionary algorithms Hybrid
    intelligent systems Systems integration Applications
    Bioinformatics Deepfake Earth sciences Finance Generative AI Art
    Audio Music Government Healthcare Mental health Industry Software
    development Translation Military Physics Projects Philosophy
    Artificial consciousness Chinese room Friendly AI Control problem
    / Takeover Ethics Existential risk Turing test Uncanny valley
    History Timeline Progress AI winter AI boom Glossary Glossary v t
    e Generative artificial intelligence ( Generative AI , GenAI , [ 1
    ] or GAI ) is a subfield of artificial intelligence that uses
    generative models to produce text, images, videos, or other forms
    of data. [ 2 ] [ 3 ] [ 4 ] These models learn the underlying
    patterns and structures of their training data and use them to
    produce new data [ 5 ] [ 6 ] based on the input, which often comes
    in the form of natural language prompts . [ 7 ] [ 8 ] Generative
    AI tools have become more common since the AI boom in the 2020s.
    This boom was made possible by improvements in transformer -based
    deep neural networks , particularly large language models (LLMs).
    Major tools include chatbots such as ChatGPT , Copilot , Gemini ,
    Claude , Grok , and DeepSeek ; text-to-image models such as Stable
    Diffusion , Midjourney , and DALL-E ; and text-to-video models
    such as Veo and Sora . [ 9 ] [ 10 ] [ 11 ] [ 12 ] Technology
    companies developing generative AI include OpenAI , Anthropic ,
    Meta AI , Microsoft , Google , DeepSeek , and Baidu . [ 7 ] [ 13 ]
    [ 14 ] Generative AI has raised many ethical questions as it can
    be used for cybercrime , or to deceive or manipulate people
    through fake news or deepfakes . [ 15 ] Even if used ethically, it
    may lead to mass replacement of human jobs . [ 16 ] The tools
    themselves have been criticized as violating intellectual property
    laws, since they are trained on copyrighted works. [ 17 ]
    Generative AI is used across many industries. Examples include
    software development, [ 18 ] healthcare, [ 19 ] finance, [ 20 ]
    entertainment, [ 21 ] customer service, [ 22 ] sales and
    marketing, [ 23 ] art, writing, [ 24 ] fashion, [ 25 ] and product
    design. [ 26 ] History [ edit ] Main article: History of
    artificial intelligence Early history [ edit ] The first example
    of an algorithmically generated media is likely the Markov chain .
    Markov chains have long been used to model natural languages since
    their development by Russian mathematician Andrey Markov in the
    early 20th century. Markov published his first paper on the topic
    in 1906, [ 27 ] [ 28 ] and analyzed the pattern of vowels and
    consonants in the novel Eugeny Onegin using Markov chains. Once a
    Markov chain is trained on a text corpus , it can then be used as
    a probabilistic text generator. [ 29 ] [ 30 ] Computers were
    needed to go beyond Markov chains. By the early 1970s, Harold
    Cohen was creating and exhibiting generative AI works created by
    AARON , the computer program Cohen created to generate paintings.
    [ 31 ] The terms generative AI planning or generative planning
    were used in the 1980s and 1990s to refer to AI planning systems,
    especially computer-aided process planning , used to generate
    sequences of actions to reach a specified goal. [ 32 ] [ 33 ]
    Generative AI planning systems used symbolic AI methods such as
    state space search and constraint satisfaction and were a
    &quot;relatively mature&quot; technology by the early 1990s. They were used
    to generate crisis action plans for military use, [ 34 ] process
    plans for manufacturing [ 32 ] and decision plans such as in
    prototype autonomous spacecraft. [ 35 ] Generative neural networks
    (2014–2019) [ edit ] See also: Machine learning and deep learning
    Above: An image classifier , an example of a neural network
    trained with a discriminative objective. Below: A text-to-image
    model , an example of a network trained with a generative
    objective. Since inception, the field of machine learning has used
    both discriminative models and generative models to model and
    predict data. Beginning in the late 2000s, the emergence of deep
    learning drove progress, and research in image classification ,
    speech recognition , natural language processing and other tasks.
    Neural networks in this era were typically trained as
    discriminative models due to the difficulty of generative
    modeling. [ 36 ] In 2014, advancements such as the variational
    autoencoder and generative adversarial network produced the first
    practical deep neural networks capable of learning generative
    models, as opposed to discriminative ones, for complex data such
    as images. These deep generative models were the first to output
    not only class labels for images but also entire images. In 2017,
    the Transformer network enabled advancements in generative models
    compared to older Long-Short Term Memory models, [ 37 ] leading to
    the first generative pre-trained transformer (GPT), known as GPT-1
    , in 2018. [ 38 ] This was followed in 2019 by GPT-2 , which
    demonstrated the ability to generalize unsupervised to many
    different tasks as a Foundation model . [ 39 ] The new generative
    models introduced during this period allowed for large neural
    networks to be trained using unsupervised learning or semi-
    supervised learning , rather than the supervised learning typical
    of discriminative models. Unsupervised learning removed the need
    for humans to manually label data , allowing for larger networks
    to be trained. [ 40 ] Generative AI boom (2020–) [ edit ] Main
    article: AI boom AI generated images have become much more
    advanced. In March 2020, the release of 15.ai , a free web
    application created by an anonymous MIT researcher that could
    generate convincing character voices using minimal training data,
    marked one of the earliest popular use cases of generative AI. [
    41 ] The platform is credited as the first mainstream service to
    popularize AI voice cloning ( audio deepfakes ) in memes and
    content creation , influencing subsequent developments in voice AI
    technology . [ 42 ] [ 43 ] In 2021, the emergence of DALL-E , a
    transformer -based pixel generative model, marked an advance in
    AI-generated imagery. [ 44 ] This was followed by the releases of
    Midjourney and Stable Diffusion in 2022, which further
    democratized access to high-quality artificial intelligence art
    creation from natural language prompts . [ 45 ] These systems
    demonstrated unprecedented capabilities in generating
    photorealistic images, artwork, and designs based on text
    descriptions, leading to widespread adoption among artists,
    designers, and the general public. In late 2022, the public
    release of ChatGPT revolutionized the accessibility and
    application of generative AI for general-purpose text-based tasks.
    [ 46 ] The system's ability to engage in natural conversations ,
    generate creative content , assist with coding, and perform
    various analytical tasks captured global attention and sparked
    widespread discussion about AI's potential impact on work ,
    education , and creativity . [ 47 ] In March 2023, GPT-4 's
    release represented another jump in generative AI capabilities. A
    team from Microsoft Research controversially argued that it &quot;could
    reasonably be viewed as an early (yet still incomplete) version of
    an artificial general intelligence (AGI) system.&quot; [ 48 ] However,
    this assessment was contested by other scholars who maintained
    that generative AI remained &quot;still far from reaching the benchmark
    of 'general human intelligence'&quot; as of 2023. [ 49 ] Later in 2023,
    Meta released ImageBind , an AI model combining multiple
    modalities including text, images, video, thermal data, 3D data,
    audio, and motion, paving the way for more immersive generative AI
    applications. [ 50 ] In December 2023, Google unveiled Gemini , a
    multimodal AI model available in four versions: Ultra, Pro, Flash,
    and Nano. [ 51 ] The company integrated Gemini Pro into its Bard
    chatbot and announced plans for &quot;Bard Advanced&quot; powered by the
    larger Gemini Ultra model. [ 52 ] In February 2024, Google unified
    Bard and Duet AI under the Gemini brand, launching a mobile app on
    Android and integrating the service into the Google app on iOS . [
    53 ] In March 2024, Anthropic released the Claude 3 family of
    large language models, including Claude 3 Haiku, Sonnet, and Opus.
    [ 54 ] The models demonstrated significant improvements in
    capabilities across various benchmarks, with Claude 3 Opus notably
    outperforming leading models from OpenAI and Google. [ 55 ] In
    June 2024, Anthropic released Claude 3.5 Sonnet, which
    demonstrated improved performance compared to the larger Claude 3
    Opus, particularly in areas such as coding, multistep workflows,
    and image analysis. [ 56 ] Private investment in AI (pink) and
    generative AI (green). Asia–Pacific countries are significantly
    more optimistic than Western societies about generative AI and
    show higher adoption rates. Despite expressing concerns about
    privacy and the pace of change, in a 2024 survey, 68% of Asia-
    Pacific respondents believed that AI was having a positive impact
    on the world, compared to 57% globally. [ 57 ] According to a
    survey by SAS and Coleman Parkes Research, China in particular has
    emerged as a global leader in generative AI adoption, with 83% of
    Chinese respondents using the technology, exceeding both the
    global average of 54% and the U.S. rate of 65%. This leadership is
    further evidenced by China's intellectual property developments in
    the field, with a UN report revealing that Chinese entities filed
    over 38,000 generative AI patents from 2014 to 2023, substantially
    surpassing the United States in patent applications. [ 58 ] A 2024
    survey on the Chinese social app Soul reported that 18% of
    respondents born after 2000 used generative AI &quot;almost every day&quot;,
    and that over 60% of respondents like or love AI-generated
    content, while less than 3% dislike or hate it. [ 59 ]
    Applications [ edit ] Notable types of generative AI models
    include generative pre-trained transformers (GPTs), generative
    adversarial networks (GANs), and variational autoencoders (VAEs).
    Generative AI systems are multimodal if they can process multiple
    types of inputs or generate multiple types of outputs. [ 60 ] For
    example, GPT-4o can both process and generate text, images and
    audio. [ 61 ] Generative AI has made its appearance in a wide
    variety of industries, radically changing the dynamics of content
    creation, analysis, and delivery. In healthcare, [ 62 ] generative
    AI is instrumental in accelerating drug discovery by creating
    molecular structures with target characteristics [ 63 ] and
    generating radiology images for training diagnostic models. This
    extraordinary ability not only enables faster and cheaper
    development but also enhances medical decision-making. In finance,
    generative AI is invaluable as it generates datasets to train
    models and automates report generation with natural language
    summarization capabilities. It automates content creation,
    produces synthetic financial data, and tailors customer
    communications. It also powers chatbots and virtual agents.
    Collectively, these technologies enhance efficiency, reduce
    operational costs, and support data-driven decision-making in
    financial institutions. [ 64 ] The media industry makes use of
    generative AI for numerous creative activities such as music
    composition, scriptwriting, video editing, and digital art. The
    educational sector is impacted as well, since the tools make
    learning personalized through creating quizzes, study aids, and
    essay composition. Both the teachers and the learners benefit from
    AI-based platforms that suit various learning patterns. [ 65 ]
    Text and software code [ edit ] Main article: Large language model
    See also: Code completion , Autocomplete , and Vibe coding Jung
    believed that the shadow self is not entirely evil or bad, but
    rather a potential source of creativity and growth. He argued that
    by embracing, rather than ignoring, our shadow self, we can
    achieve a deeper understand

------------------------------------------------------------


---------- ✨ RESULT #3 ✨ ----------------------------------------

  📌 Title: What is Generative AI? - GeeksforGeeks
  🌐 URL  : https://www.geeksforgeeks.org/artificial-intelligence/what-is-generative-ai/

  📊 Detailed Analysis (General Web Page):
    - Url: https://www.geeksforgeeks.org/artificial-intelligence/what-is-generative-ai/
    - Title: What is Generative AI? - GeeksforGeeks
    - Meta Description: Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.
    - Main Heading: What is Generative AI?
    - Summary Text: Generative artificial intelligence, often called generative AI or gen AI, is a type of AI that can create new content like conversations, stories, images, videos, and music. It can learn about different topics such as languages, programming, art, science, and more, and use this knowledge to solve new problems. For example: It can learn about popular design styles and create a unique logo for a brand or an organisation. Businesses can use generative AI in many ways, like building chatbots, creating media, designing products, and coming up with new ideas. Generative AI has come a long way from its early beginnings. Here's how it has evolved over time, step by step: Generative AI is versatile, with different models designed for specific tasks. Here are some types:
    - Links: (Complex Data - See raw content)
    - Keywords: Generative AI, machine learning, deep learning, Generative Adversarial Networks, Large Language Models, multimodal generative AI, text-to-image generation, image-to-image transformation, speech-to-text technology, text-to-video models, creative content generation, personalized marketing campaigns, ethical concerns in AI, AI-powered design tools
    - Author: GeeksforGeeks
    - Published Date: 2023-08-16 12:11:46+00:00
    - Structured Data: (Complex Data - See raw content)

  📄 Raw Content Excerpt:
    What is Generative AI? - GeeksforGeeks Data Science Data Science
    Projects Data Analysis Data Visualization Machine Learning ML
    Projects Deep Learning NLP Computer Vision Artificial Intelligence
    Open In App Next Article: Generative Adversarial Network (GAN)
    What is Generative AI? Last Updated : 23 Jan, 2025 Summarize
    Comments Improve Suggest changes Share Like Article Like Report
    Generative artificial intelligence, often called generative AI or
    gen AI, is a type of AI that can create new content like
    conversations, stories, images, videos, and music. It can learn
    about different topics such as languages, programming, art,
    science, and more, and use this knowledge to solve new problems.
    For example: It can learn about popular design styles and create a
    unique logo for a brand or an organisation. Businesses can use
    generative AI in many ways, like building chatbots, creating
    media, designing products, and coming up with new ideas. Evolution
    of Generative AI Generative AI has come a long way from its early
    beginnings. Here's how it has evolved over time, step by step: 1.
    The Early Days: Rule-Based Systems AI systems followed strict
    rules written by humans to produce results. These systems could
    only do what they were programmed for and couldn't learn or adapt.
    For example, a program could create simple shapes but couldn’t
    draw something creative like a landscape. 2. Introduction of
    Machine Learning (1990s-2000s) AI started using machine learning,
    which allowed it to learn from data instead of just following
    rules. The AI was fed large datasets (e.g., pictures of animals),
    and it learned to identify patterns and make predictions. Example:
    AI could now recognize a dog in a picture, but it still couldn’t
    create a picture of a dog on its own. 3. The Rise of Deep Learning
    (2010s) Deep learning improved AI significantly by using neural
    networks, which mimic how the human brain works. AI could now
    process much more complex data, like thousands of photos, and
    start generating new content. Example: AI could now create a
    realistic drawing of a dog by learning from millions of dog
    photos. 4. Generative Adversarial Networks (2014) GANs, introduced
    in 2014, use two AI systems that work together: one generates new
    content, and the other checks if it looks real. This made
    generative AI much better at creating realistic images, videos,
    and sounds. Example: GANs can create life like images of people
    who don’t exist or filters (used in apps like FaceApp or Snapchat
    ). 5. Large Language Models (LLMs) and Beyond (2020s) Models like
    GPT-3 and GPT-4 can understand and generate human-like text. They
    are trained on massive amounts of data from books, websites, and
    other sources. AI can now hold conversations, write essays,
    generate code, and much more. Example: ChatGPT can help you draft
    an email, write a poem, or even solve problems. 6. Multimodal
    Generative AI (Present) New AI models can handle multiple types of
    data at once—text, images, audio, and video. This allows AI to
    create content that combines different formats. Example: AI can
    take a written description and turn it into an animated video or a
    song with the help of different models integrating together. Types
    of Generative AI Models Generative AI is versatile, with different
    models designed for specific tasks. Here are some types: Text-to-
    Text : These models generate meaningful and coherent text based on
    input text. They are widely used for tasks like drafting emails,
    summarizing lengthy documents, translating languages, or even
    writing creative content. Tools like ChatGPT is brilliant at
    understanding context and producing human-like responses. Text-to-
    Image : This involves generating realistic images from descriptive
    text. For Example, tools like DALL-E 2 can create a custom digital
    image based on prompts such as &quot;A peaceful beach with palm trees
    during a beautiful sunset,&quot; offering endless possibilities for
    designers, artists, and marketers. Image-to-Image : These models
    enhance or transform images based on input image . For example,
    they can convert a daytime photo into a night time scene, apply
    artistic filters, or refine low-resolution images into high-
    quality visuals. Image-to-Text : AI tools analyze and describe the
    content of images in text form. This technology is especially
    beneficial for accessibility, helping visually impaired
    individuals understand visual content through detailed captions.
    Speech-to-Text : This application converts spoken words into
    written text. It powers virtual assistants like Siri,
    transcription software, and automated subtitles, making it a vital
    tool for communication, accessibility, and documentation. Text-to-
    Audio : Generative AI can create music, sound effects, or audio
    narrations from textual prompts. This empowers creators to explore
    new soundscapes and compose unique auditory experiences tailored
    to specific themes or moods. Text-to-Video : These models allow
    users to generate video content by describing their ideas in text.
    For example, a marketer could input a vision for a promotional
    video, and the AI generates visuals and animations, streamlining
    content creation. Multimodal AI : These systems integrate multiple
    input and output formats, like text, images, and audio, into a
    unified interface. For instance, an educational platform could let
    students ask questions via text and receive answers as interactive
    visuals or audio explanations, enhancing learning experiences.
    Relationship Between Humans and Generative AI In today’s world,
    Generative AI has become a trusted best friend for humans, working
    alongside us to achieve incredible things. Imagine a painter
    creating a masterpiece, while they focus on the vision, Generative
    AI acts as their assistant, mixing colors, suggesting designs, or
    even sketching ideas. The painter remains in control, but the AI
    makes the process faster and more exciting. This partnership is
    like having a friend who’s always ready to help. A writer stuck on
    the opening line of a story can turn to Generative AI for
    suggestions that spark creativity. A business owner without design
    skills can rely on AI to draft a sleek website or marketing
    materials. Even students can use AI to better understand complex
    topics by generating easy-to-grasp explanations or visual aids.
    Generative AI is not here to replace humans but to empower them.
    It takes on repetitive tasks, offers endless possibilities, and
    helps people achieve results they might not have imagined alone.
    At the same time, humans bring their intuition, creativity, and
    ethical judgment, ensuring the AI’s contributions are meaningful
    and responsible. In this era, Generative AI truly feels like a
    best friend—always there to support, enhance, and inspire us while
    letting us stay in charge. Together, humans and AI make an
    unbeatable team, achieving more than ever before. Generative AI Vs
    AI Criteria Generative AI Artificial Intelligence Purpose It is
    designed to produce new content or data Designed for a wide range
    of tasks but not limited to generation Application Art creation,
    text generation, video synthesis, and so on Data analysis,
    predictions, automation, robotics, etc Learning Uses Unsupervised
    learning or reinforcement learning Can use supervised, semi-
    supervised, or reinforcement Outcome New or original output is
    created Can produce an answer and make a decision, classify, data,
    etc. Complexity It requires a complex model like GANs It has
    ranged from simple linear regression to complex neural networks
    Data Requirement Required a large amount of data to produce
    results of high-quality data Data requirements may vary; some need
    little data, and some need vast amounts Interactivity Can be
    interactive, responding to user input Might not always be
    interactive, depending on the application Benefits of Generative
    AI Generative AI offers innovative tools that enhance creativity,
    efficiency, and personalization across various fields. Enhances
    Creativity : Generative AI enables the creation of original
    content like images, music, and text, helping artists, designers,
    and writers explore fresh ideas. It bridges the gap between human
    creativity and machine-generated innovation, making the creative
    process more dynamic. Accelerates Research and Development : In
    fields like science and technology, Generative AI reduces the time
    needed for research by generating multiple outcomes and
    predictions, such as molecular structures in drug development.
    This speeds up innovation and helps solve complex problems
    efficiently. Improves Personalization : Generative AI creates
    tailored content based on user preferences. From personalized
    product designs to customized marketing campaigns, it enhances
    user engagement and satisfaction by delivering exactly what users
    need or want. Empowers Non-Experts : Even users without expertise
    can create high-quality content using Generative AI. This helps
    individuals learn new skills, access creative tools, and open
    doors to personal and professional growth. Drives Economic Growth
    : Generative AI introduces new roles and opportunities by
    fostering innovation, automating tasks, and enhancing
    productivity. This leads to economic expansion and the creation of
    jobs in emerging fields. Limitations of Generative AI While
    Generative AI offers many benefits, it also comes with certain
    limitations that need to be addressed Data Dependence : The
    accuracy and quality of Generative AI outputs depend entirely on
    the data it is trained on. If the training data is biased,
    incomplete, or inaccurate, the generated content will reflect
    these flaws. Limited Control Over Outputs : Generative AI can
    produce unexpected or irrelevant results, making it challenging to
    control the content and ensure it aligns with specific user
    requirements. High Computational Requirements : Training and
    running Generative AI models demand significant computing power,
    which can be costly and resource-intensive. This limits
    accessibility for smaller organizations or individuals. Ethical
    and Legal Concerns : Generative AI can be misused to create
    harmful content, like deepfakes or fake news, which can spread
    misinformation or violate privacy. These ethical and legal
    challenges require careful regulation and oversight to prevent
    abuse. Q1. Is generative AI replacing jobs? Generative AI isn’t
    about replacing jobs but transforming them. It automates
    repetitive tasks, allowing people to focus on more creative and
    strategic aspects of their work. For example, content writers can
    use AI for inspiration or to speed up first drafts, while
    designers can use it to generate quick mockups. Q2. How does
    Generative AI work? Generative AI works by teaching computer
    programs (like GPT-3 or GANs) from lots of examples. These
    programs learn how things are usually done from the data they
    study. Then, they can use this knowledge to create new stuff when
    given a starting point or a request. Q3. What are common use cases
    for Generative AI? Generative AI has a wide range of applications,
    including content generation, language translation, chatbots,
    image and video creation, data augmentation, and personalized
    marketing. It can also be used in artistic creation, medical image
    generation, and more. Q4. Is Generative AI different from other AI
    types? Yes, Generative AI is different from other AI types, like
    classification or regression models. While those models make
    predictions or classify data, generative models focus on creating
    new, original data based on the patterns they’ve learned. They are
    versatile and used for creative tasks. Q5. How can I get started
    with generative AI? You can start by exploring tools and platforms
    like ChatGPT for text generation, DALL-E for image generation, or
    similar tools for your needs. Many platforms also provide APIs,
    allowing developers to integrate AI capabilities into their own
    applications. Learning basic prompt engineering can also help you
    get the most out of these tools. Next Article Generative
    Adversarial Network (GAN) A anushka_jain_gfg Improve Article Tags
    : Artificial Intelligence AI-ML-DS Generative AI Similar Reads
    Artificial Intelligence Tutorial | AI Tutorial Artificial
    Intelligence (AI) refers to the simulation of human intelligence
    in machines which helps in allowing them to think and act like
    humans. It involves creating algorithms and systems that can
    perform tasks which requiring human abilities such as visual
    perception, speech recognition, decisio 5 min read Introduction to
    AI What is Artificial I

------------------------------------------------------------


======================================================================
                   ✨ Scraping Process Completed ✨
======================================================================
</code></pre>
</doc-codeblock></div>
</doc-panel>
<doc-anchor-target id="cloudflare-worker-jina-ai--groq-scraper">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#cloudflare-worker-jina-ai--groq-scraper">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M3.103 10.107c0-4.244 3.445-7.607 7.733-7.607 3.19 0 5.912 1.858 7.099 4.563l.01.022.001.006C21.348 7.345 24 10.095 24 13.536 24 17.148 21.076 20 17.431 20H5.017C2.23 20 0 17.83 0 15.06a4.899 4.899 0 0 1 3.112-4.581 7.696 7.696 0 0 1-.009-.372ZM10.836 4c-3.485 0-6.233 2.717-6.233 6.107 0 .284.022.602.052.756a.75.75 0 0 1-.552.869c-1.52.385-2.603 1.712-2.603 3.328 0 1.917 1.532 3.44 3.517 3.44h12.414c2.843 0 5.069-2.206 5.069-4.964 0-2.759-2.226-4.965-5.069-4.965a.75.75 0 0 1-.696-.47l-.179-.446C15.606 5.5 13.424 4 10.836 4Z"/></g></g></svg> Cloudflare Worker Jina AI &amp; Groq Scraper</span>
    </h2>
</doc-anchor-target>
<doc-anchor-target id="features-1">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#features-1">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M21.03 5.72a.75.75 0 0 1 0 1.06l-11.5 11.5a.747.747 0 0 1-1.072-.012l-5.5-5.75a.75.75 0 1 1 1.084-1.036l4.97 5.195L19.97 5.72a.75.75 0 0 1 1.06 0Z"/></g></g></svg> Features</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Leverages Jina AI and DuckDuckGo for search</li>
<li>Analyzes content with Groq LLM API</li>
<li>Rotates multiple API keys via GetPantry</li>
<li>Deploys serverless on Cloudflare Workers</li>
</ul>
<doc-anchor-target id="setup">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#setup">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M10.75 6.5a.75.75 0 0 0 0 1.5h6.5a.75.75 0 0 0 0-1.5h-6.5ZM6 7.25a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 6 7.25Zm4 9a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-3.25-.75a.75.75 0 0 0 0 1.5h.5a.75.75 0 0 0 0-1.5h-.5Z"/><path d="M3.25 2h17.5c.966 0 1.75.784 1.75 1.75v7c0 .372-.116.716-.314 1 .198.284.314.628.314 1v7a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75v-7c0-.358.109-.707.314-1a1.741 1.741 0 0 1-.314-1v-7C1.5 2.784 2.284 2 3.25 2Zm0 10.5a.25.25 0 0 0-.25.25v7c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-7a.25.25 0 0 0-.25-.25Zm0-1.5h17.5a.25.25 0 0 0 .25-.25v-7a.25.25 0 0 0-.25-.25H3.25a.25.25 0 0 0-.25.25v7c0 .138.112.25.25.25Z"/></g></g></svg> Setup</span>
    </h3>
</doc-anchor-target>
<ol>
<li>Open the <code v-pre>Cloudflare Worker: Jina AI &amp; Groq Scraper</code> folder</li>
<li>Edit <code v-pre>worker.js</code>: replace <code v-pre>JINA_API_KEYS</code>, <code v-pre>GROQ_API_KEYS</code>, <code v-pre>PANTRY_ID</code>, and <code v-pre>BASKET_NAME</code></li>
<li><p>Initialize Pantry basket with:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-json"><code v-pre class="language-json">{&quot;jina&quot;: 0, &quot;groq&quot;: 0}</code></pre>
</doc-codeblock></div>
</li>
<li>Deploy the script to Cloudflare Workers</li>
</ol>
<doc-anchor-target id="invoke-endpoint">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#invoke-endpoint">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M9.5 15.584V8.416a.5.5 0 0 1 .77-.42l5.576 3.583a.5.5 0 0 1 0 .842l-5.576 3.584a.5.5 0 0 1-.77-.42Z"/><path d="M1 12C1 5.925 5.925 1 12 1s11 4.925 11 11-4.925 11-11 11S1 18.075 1 12Zm11-9.5A9.5 9.5 0 0 0 2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5Z"/></g></g></svg> Invoke Endpoint</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-bash"><code v-pre class="language-bash">GET https://&lt;your-worker&gt;/?query=your+search+term&amp;key=&lt;your-api-key&gt;</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="live-demo">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#live-demo">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M15.5 12a3.5 3.5 0 1 1-7 0 3.5 3.5 0 0 1 7 0Z"/><path d="M12 3.5c3.432 0 6.124 1.534 8.054 3.241 1.926 1.703 3.132 3.61 3.616 4.46a1.6 1.6 0 0 1 0 1.598c-.484.85-1.69 2.757-3.616 4.461-1.929 1.706-4.622 3.24-8.054 3.24-3.432 0-6.124-1.534-8.054-3.24C2.02 15.558.814 13.65.33 12.8a1.6 1.6 0 0 1 0-1.598c.484-.85 1.69-2.757 3.616-4.462C5.875 5.034 8.568 3.5 12 3.5ZM1.633 11.945a.115.115 0 0 0-.017.055c.001.02.006.039.017.056.441.774 1.551 2.527 3.307 4.08C6.691 17.685 9.045 19 12 19c2.955 0 5.31-1.315 7.06-2.864 1.756-1.553 2.866-3.306 3.307-4.08a.111.111 0 0 0 .017-.056.111.111 0 0 0-.017-.056c-.441-.773-1.551-2.527-3.307-4.08C17.309 6.315 14.955 5 12 5 9.045 5 6.69 6.314 4.94 7.865c-1.756 1.552-2.866 3.306-3.307 4.08Z"/></g></g></svg> Live Demo</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-bash"><code v-pre class="language-bash">GET https://webscrape.0xcloud.workers.dev/?key=test&amp;query=your+query</code></pre>
</doc-codeblock></div>
<blockquote>
<p><code v-pre>test</code> key gives daily 15 queries</p>
</blockquote>

                                <div id="retype-tags" class="flex items-center mt-6 mb-6 clear-both">
                                    <span>
                                        <a href="../tags/">
                                            <svg class="inline-block -mb-px mr-1.5 text-body-link hover:text-body-link-hover" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" overflow="visible" fill="currentColor"><g><path d="M21.3 9.88l-8.59-8.59C12.52 1.11 12.27 1 12 1H2c-.55 0-1 .45-1 1v10c0 .27.11.52.29.71l8.59 8.58c.57.57 1.32.88 2.12.88s1.55-.31 2.12-.88l7.17-7.17a3.009 3.009 0 00.01-4.24zm-1.42 2.82l-7.17 7.17c-.39.39-1.02.39-1.42 0L3 11.59V3h8.59l8.29 8.29c.39.39.39 1.03 0 1.41z" /><path d="M7.01 6C6.45 6 6 6.45 6 7s.45 1 1 1 1-.45 1-1-.44-1-.99-1z" /></g></svg>
                                        </a>
                                        <span class="mr-2"><a href="../tags/python/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>python</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/cloudflare/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>cloudflare</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/fastapi/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>fastapi</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/ai/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>ai</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/duckduckgo/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>duckduckgo</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/jina/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>jina</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/groq/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>groq</span>
                                </a></span>
                                        <span class="mr-2"><a href="../tags/pantrycloud/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-badge-info-text bg-badge-info border border-badge-info-border hover:text-badge-info-text-hover hover:bg-badge-info-hover hover:border-badge-info-border-hover transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
                                    <span>pantrycloud</span>
                                </a></span>
                                    </span>
                                </div>
                
                                <!-- Required only on API pages -->
                                <doc-toolbar-member-filter-no-results></doc-toolbar-member-filter-no-results>
                            </div>
                            <footer id="retype-content-footer" class="clear-both">
                            
                                <nav id="retype-nextprev" class="print:hidden flex mt-14">
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 h-full flex items-center break-normal font-medium text-body-link border border-base-border hover:border-base-border-hover rounded-l-lg transition-colors duration-150 relative hover:z-5" href="../aiclassroomassistant/">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                            <span>
                                                <span class="block text-xs font-normal text-base-text-muted">Previous</span>
                                                <span class="block mt-1">AI Classroom Teaching Assistant System</span>
                                            </span>
                                        </a>
                                    </div>
                            
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-normal font-medium text-body-link border border-base-border hover:border-base-border-hover rounded-r-lg transition-colors duration-150 relative hover:z-5" href="../githubprofileanalyser/">
                                            <span>
                                                <span class="block text-xs font-normal text-right text-base-text-muted">Next</span>
                                                <span class="block mt-1">Git​Hub Profile Analyzer</span>
                                            </span>
                                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                        </a>
                                    </div>
                                </nav>
                            </footer>
                        </main>
                
                        <div id="retype-page-footer" class="print:border-none border-t border-base-border pt-6 mb-8">
                            <footer class="flex flex-wrap items-center justify-between print:justify-center">
                                <div id="retype-footer-links" class="print:hidden">
                                    <ul class="flex flex-wrap items-center text-sm">
                                        <li>
                                            <a class="block mr-4 py-2 text-sm whitespace-nowrap transition-colors duration-200 ease-linear text-footer-link hover:text-footer-link-hover md:mb-0" href="https://github.com/0xarchit">GitHub</a>
                                        </li>
                                        <li>
                                            <a class="block mr-4 py-2 text-sm whitespace-nowrap transition-colors duration-200 ease-linear text-footer-link hover:text-footer-link-hover md:mb-0" href="https://www.linkedin.com/in/0xarchit/">LinkedIn</a>
                                        </li>
                                        <li>
                                            <a class="block mr-4 py-2 text-sm whitespace-nowrap transition-colors duration-200 ease-linear text-footer-link hover:text-footer-link-hover md:mb-0" href="https://x.com/0xarchit">Twitter</a>
                                        </li>
                                    </ul>
                                </div>
                                <div id="retype-copyright" class="print:justify-center py-2 text-footer-text font-footer-link-weight text-sm leading-relaxed"><p>© 2025 0xArchit. All rights reserved.</p></div>
                            </footer>
                        </div>
                    </div>
                
                    <!-- Rendered if sidebar right is enabled -->
                    <!-- Sidebar right skeleton-->
                    <div v-cloak class="fixed top-0 bottom-0 right-0 translate-x-full bg-sidebar-right-bg border-sidebar-right-border lg:sticky lg:border-l lg:shrink-0 lg:pt-6 lg:transform-none sm:w-1/2 lg:w-64 lg:z-0 md:w-104 sidebar-right skeleton">
                        <div class="pl-5">
                            <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                            <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                            <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                        </div>
                    </div>
                
                    <!-- User should be able to hide sidebar right -->
                    <doc-sidebar-right v-cloak></doc-sidebar-right>
                </div>

            </div>
        </div>
    
        <doc-search-mobile></doc-search-mobile>
        <doc-back-to-top></doc-back-to-top>
    </div>


    <div id="retype-overlay-target"></div>

    <script data-cfasync="false">window.__DOCS__ = { "title": "Web Scraper Collection", level: 1, icon: "file", hasPrism: true, hasMermaid: false, hasMath: false, tocDepth: 23 }</script>
</body>
</html>
